#version 450
#extension GL_ARB_separate_shader_objects : enable

#define WORKGROUP_SIZE 32
layout (local_size_x = WORKGROUP_SIZE, local_size_y = WORKGROUP_SIZE) in;
layout (binding = 0, rgba8) uniform writeonly image2D resultImage;

layout (binding = 1) uniform UniformBufferObject {
    mat4 model;
    mat4 view;
    mat4 proj;
    vec3 pos;
} ubo;

struct Intersection {
    vec3 normal;
    vec3 point;
    bool valid;
    float t;
};

#define ATMOSPHERE_RADIUS 1000000.0
#define LIGHT_VEC normalize(vec3(1, 1, 0))
#define BLOB_CLOUD_STEP_SIZE ATMOSPHERE_RADIUS / 100.0
#define NUM_FBM_OCTAVES 8
#define EPSILON 0.0001

//#define VISUALIZE_NOISE

// TODO: pass fovy as a descriptor set
// Overall fovy of 45
#define FOVY_OVER_2 22.5
#define ASPECT_RATIO dim.x / dim.y

// Compute sphere intersection
Intersection raySphereIntersection(in vec3 ro, in vec3 rd, in vec4 sphere) {
	Intersection isect;
    isect.valid = false;
    isect.point = vec3(0);
    isect.normal = vec3(0, 1, 0);
    
    // no rotation, only uniform scale, always a sphere
    ro -= sphere.xyz;
    ro /= sphere.w;
    
    float A = dot(rd, rd);
    float B = 2.0 * dot(rd, ro);
    float C = dot(ro, ro) - 0.25;
    float discriminant = B * B - 4.0 * A * C;
    
    if (discriminant < 0.0) return isect;
    float t = (-sqrt(discriminant) - B) / A * 0.5;
    if (t < 0.0) t = (sqrt(discriminant) - B) / A * 0.5;
    
    if (t >= 0.0) {
        isect.valid = true;
    	vec3 p = vec3(ro + rd * t);
        isect.normal = normalize(p);
        p *= sphere.w;
        p += sphere.xyz;
        isect.point = p;
        isect.t = length(p - ro);
    }
    
    return isect;
}

// Procedural noise function for Fractal Brownian Motion taken from here: https://thebookofshaders.com/13/
float noise(in vec2 p) { 
    return fract(sin(dot(p, vec2(12.9898, 78.233))) * 43758.5453123);
}

float interpolateNoise(in vec2 p) {
    vec2 p_floor = floor(p);
    vec2 p_fract = p - p_floor;

    // Sample the noise function at grid intervals
    vec2 offset = vec2(0.0, 1.0);
    float noise00 = noise(p_floor);
    float noise01 = noise(p_floor + offset);
    float noise10 = noise(p_floor + offset.yx);
    float noise11 = noise(p_floor + offset.yy);

    // Bilinearly interpolate
    float noise_x1 = mix(noise00, noise10, p_fract.x);
    float noise_x2 = mix(noise01, noise11, p_fract.x);

    return mix(noise_x1, noise_x2, p_fract.y);
}

float remap(in float value, in float oldMin, in float oldMax, in float newMin, in float newMax) {
    return newMin + (((value - oldMin) / (oldMax - oldMin)) * (newMax - newMin));
}

float FBM(in vec2 p) {
    float amplitude = 0.75;
    float frequency = 1.0;
    const float persistence = 0.5;
    float maxVal = 0.0;
    float accumNoise = 0.0;

    for(int i = 0; i < NUM_FBM_OCTAVES; ++i) {
        accumNoise += interpolateNoise(p * frequency) * amplitude;
        maxVal += amplitude;
        amplitude *= persistence;
        frequency *= 2.0;
    }

    float noiseVal = accumNoise / maxVal;
    noiseVal *= step(0.5, noiseVal);
    return remap(noiseVal, 0.5, 1.0, 0.0, 1.0);
}

void main() {
    /// Extract the UV
    ivec2 dim = imageSize(resultImage);
	vec2 uv = vec2(gl_GlobalInvocationID.xy) / dim;
    /// Cast a ray
    
    // Compute screen space point from UVs
    vec2 screenPoint = uv * 2.0 - 1.0;
    //screenPoint.x *= dim.x / dim.y; // TODO: aspect ratio as uniform

    // Extract camera information from uniform
    //vec3 camRight = vec3(ubo.view[0][0], ubo.view[0][1], ubo.view[0][2]); // should normalize these but that could slow things down
    //vec3 camUp = vec3(ubo.view[1][0], ubo.view[1][1], ubo.view[1][2]);
    vec3 camLook = vec3(ubo.view[0][2], ubo.view[1][2], ubo.view[2][2]);
    vec3 camRight = vec3(ubo.view[0][0], ubo.view[1][0], ubo.view[2][0]);
    vec3 camUp = vec3(ubo.view[0][1], ubo.view[1][1], ubo.view[2][1]);

    // Compute ray direction
    vec3 cameraPos = ubo.pos;
    vec3 refPoint = cameraPos - camLook;

    const float tanFovy = 0.4142135;
    vec3 screenH = tanFovy * camUp; // TODO should multiply by length(refPoint - cameraPos) if the refPoint changes
    vec3 screenW = tanFovy * ASPECT_RATIO * camRight;

    vec3 p = refPoint + ASPECT_RATIO * screenPoint.x * tanFovy * camRight - screenPoint.y * tanFovy * camUp;	

    vec3 rayDirection = normalize(p - cameraPos);

    // It is likely we will never have an entirely unobstructed view of the horizon, so kill rays that would otherwise be executing.
    // This should be handled by the stenciling thing though
    if(dot(rayDirection, vec3(0, 1, 0)) < 0.0) {
        imageStore(resultImage, ivec2(gl_GlobalInvocationID.xy), vec4(0, 0, 0, 1));
        return;
    }

    //vec3 col = 0.5 + 0.5 * rayDirection;
    //imageStore(resultImage, ivec2(gl_GlobalInvocationID.xy), vec4(col.xxx, 1));
    //return;

    /// Raytrace the scene (a sphere, to become the atmosphere)
    vec3 earthCenter = cameraPos;
    earthCenter.y = -ATMOSPHERE_RADIUS * 0.5 * 0.9;
    vec4 atmosphereSphereInner = vec4(earthCenter, ATMOSPHERE_RADIUS);
    vec4 atmosphereSphereOuter = vec4(earthCenter, ATMOSPHERE_RADIUS * 1.05);
    Intersection atmosphereIsectInner = raySphereIntersection(cameraPos, rayDirection, atmosphereSphereInner);
    Intersection atmosphereIsectOuter = raySphereIntersection(cameraPos, rayDirection, atmosphereSphereOuter);

    /*
    if (atmosphereIsectInner.valid) {
        vec2 samplePoint = (atmosphereIsectInner.point.xz - cameraPos.xz) / 10000.0;
        float density = FBM(samplePoint);
        vec3 col = 0.5 + 0.5 * atmosphereIsectInner.normal;
        col = vec3(clamp(atmosphereIsectInner.point, vec3(0), vec3(1)));
        col = vec3(density);
        imageStore(resultImage, ivec2(gl_GlobalInvocationID.xy), vec4(col.xyz, 1));
        return;
    } else {
        imageStore(resultImage, ivec2(gl_GlobalInvocationID.xy), vec4(0, 0, 0, 1));
        return;
    }
    */

    // Preliminary and not physically-based volume integration
    float t, dt;
    float accumDensity = 0.0;
    dt = BLOB_CLOUD_STEP_SIZE;
    float numSteps = floor(mix(32, 64, 1.0 - rayDirection.y));
    float stepSize = (atmosphereIsectOuter.t - atmosphereIsectInner.t) / numSteps;

    for(float t = atmosphereIsectInner.t; t < atmosphereIsectOuter.t; t += stepSize) {
        vec3 currentPos = cameraPos + t * rayDirection;
        
        float yRelative = (t - atmosphereIsectInner.t) / (atmosphereIsectOuter.t - atmosphereIsectInner.t);
        yRelative = remap(yRelative, 0.0, 0.3, 0.0, 1.0) * remap(yRelative, 0.7, 1.0, 1.0, 0.0);

        vec2 samplePoint = (currentPos.xz - cameraPos.xz) / 20000.0;
        float density = FBM(samplePoint);

        // Compute the light contribution using Lambertian shading and directional derivative
        // http://www.iquilezles.org/www/articles/derivative/derivative.htm
        if(density > 0.0) {
            //accumDensity += FBM(samplePoint + EPSILON * LIGHT_VEC.xz) - density;
            accumDensity += yRelative * density;
            //break;
        }
        
        if(accumDensity > 0.99) {
            accumDensity = 1.0;
            break;
        }
    }
    accumDensity *= remap(sqrt(max(0.0, rayDirection.y)) + 0.2, 0.2, 1.2, 0, 1);
    vec4 finalColor = vec4(accumDensity, accumDensity, accumDensity, 1);

    imageStore(resultImage, ivec2(gl_GlobalInvocationID.xy), finalColor);
}
